{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import the necessary libraries, including requests, json, pandas, and IPython.display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pandas IPython matplotlib numpy ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Input Data and Prompt\n",
    "Load the input text and prompt template from the specified file paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input file path\n",
    "input_file_path = Path('../data/raw_text/raw_text_20241213_175758.txt')\n",
    "\n",
    "# Set the prompt file path\n",
    "prompt_file_path = Path('../backend/extraction/prompts/prompt_v1.txt')\n",
    "\n",
    "# Set the system message file path\n",
    "system_message_file_path = Path('../backend/extraction/prompts/system_message_v0.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of input text:\n",
      "/* Metadata:\n",
      "{\n",
      "  \"timestamp\": \"20241213_175758\",\n",
      "  \"characters\": 48692,\n",
      "  \"lines\": 1\n",
      "}\n",
      "*/\n",
      "\n",
      "<<< Return to selection page Campus: Blacksbur g - Term: Fall 2024 CRN Course TitleSchedule TypeModalityCr Hr...\n"
     ]
    }
   ],
   "source": [
    "# Function to load text from a file\n",
    "def load_text_file(file_path: str) -> str:\n",
    "    \"\"\"Load text from file\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read().strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading file {file_path}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load input text and prompt\n",
    "input_text = load_text_file(input_file_path)\n",
    "prompt = load_text_file(prompt_file_path)\n",
    "system_message = load_text_file(system_message_file_path)\n",
    "\n",
    "# Format full prompt\n",
    "full_prompt = prompt.format(text=input_text)\n",
    "\n",
    "print(\"Sample of input text:\")\n",
    "print(input_text[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test LLM Extraction\n",
    "Call the Ollama API with the formatted prompt, parse the results, and save them to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_ollama(prompt: str, system_prompt: str, temperature: float = 0.2) -> str:\n",
    "    \"\"\"Call Ollama API with the given prompt\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            'http://localhost:11434/api/generate',\n",
    "            json={\n",
    "                'model': 'qwen2.5:14b-instruct',\n",
    "                'system': system_prompt,\n",
    "                'prompt': prompt,\n",
    "                'stream': False,\n",
    "                'temperature': temperature\n",
    "            }\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()['response']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error calling Ollama API: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def parse_course_data(llm_output: str) -> List[Dict]:\n",
    "    \"\"\"Parse LLM output into structured course data\"\"\"\n",
    "    try:\n",
    "        # Assuming LLM outputs JSON format\n",
    "        courses = json.loads(llm_output)\n",
    "        if not isinstance(courses, list):\n",
    "            courses = [courses]\n",
    "        return courses\n",
    "    except json.JSONDecodeError as e:\n",
    "        logging.error(f\"Error parsing LLM output as JSON: {str(e)}\")\n",
    "        logging.error(f\"Raw output: {llm_output}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 14:53:19,258 - INFO - Calling Ollama API...\n",
      "2024-12-13 14:54:16,050 - ERROR - Error parsing LLM output as JSON: Expecting value: line 1 column 1 (char 0)\n",
      "2024-12-13 14:54:16,064 - ERROR - Raw output: Based on the provided course information from Virginia Tech, here are the key details for AOE-7994 (Research and Dissertation) offered both in-person and online during Fall 2023:\n",
      "\n",
      "### In-Person Sections:\n",
      "1. **CRN 80711:**\n",
      "   - Instructor: SS Choi\n",
      "   - Days/Time: Monday, Wednesday, Friday from 12:30 PM to 1:20 PM\n",
      "   - Room: McBryde Hall (MB) 450\n",
      "\n",
      "2. **CRN 80719:**\n",
      "   - Instructor: EG Paterson\n",
      "   - Days/Time: Tuesday and Thursday from 11:00 AM to 12:15 PM\n",
      "   - Room: Randolph Hall (RA) 309\n",
      "\n",
      "### Online Sections:\n",
      "1. **CRN 80723:**\n",
      "   - Instructor: AJ Brown, SL England, WJ Devinport, GD Seidel, and more\n",
      "   - Format: Virtual Campus (VR)\n",
      "   - Comments: \"Virtual campus\"\n",
      "\n",
      "2. **CRN 80727:**\n",
      "   - Instructor: CA Woolsey, G Young, JT Black\n",
      "   - Format: Virtual Campus (VR)\n",
      "   - Comments: \"online\"\n",
      "\n",
      "3. **CRN 92400:**\n",
      "   - Instructor: KK Schroeder\n",
      "   - Format: Online: Asynchronous\n",
      "   - Days/Time: Not specified (Online)\n",
      "   - Comments: \"OnLine: Asynchronous\"\n",
      "\n",
      "### General Notes:\n",
      "- All sections are listed as \"ARR\" which indicates that enrollment is arranged.\n",
      "- Each section has a capacity of 10 students.\n",
      "\n",
      "For more detailed information, it would be best to consult with your academic advisor or the course instructor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted 0 courses. Results saved to extracted_courses_20241213_145416.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test LLM Extraction\n",
    "\n",
    "# Call LLM\n",
    "logging.info(\"Calling Ollama API...\")\n",
    "llm_output = call_ollama(full_prompt, system_message)\n",
    "\n",
    "# Parse results\n",
    "courses = parse_course_data(llm_output)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(courses)\n",
    "\n",
    "# Save results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_file = f\"extracted_courses_{timestamp}.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nExtracted {len(courses)} courses. Results saved to {output_file}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "Calculate and display quality metrics for the extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "def calculate_metrics(df: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Calculate quality metrics for extracted data\"\"\"\n",
    "    metrics = {\n",
    "        'total_courses': len(df),\n",
    "        'completeness': {}\n",
    "    }\n",
    "    \n",
    "    # Calculate completeness for each field\n",
    "    for column in df.columns:\n",
    "        non_null = df[column].notna().sum()\n",
    "        completeness = (non_null / len(df)) * 100 if len(df) > 0 else 0\n",
    "        metrics['completeness'][column] = round(completeness, 2)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate and display metrics\n",
    "metrics = calculate_metrics(df)\n",
    "print(\"\\nExtraction Metrics:\")\n",
    "print(json.dumps(metrics, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
